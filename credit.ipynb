{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit approval \n",
    "데이터는 신용 승인 여부를 판단하는 데이터로 class가 target으로 +,-로 나뉜다.\n",
    "나머지 데이터는 개인정보로 의미없는 기호로 코딩되어있으며 결측치가 있어 이를 처리하여야한다.\n",
    "또한 연속척도와 순서척도가 섞여있어 분석 전 이를 미리 분류하고 학습시켜야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15  target\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0       0\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560       0\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824       0\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3       0\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0       0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 열 이름의 공백, class-> target으로 바꾸기 위해열 이름을 다시 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11',\n",
    "       'A12', 'A13', 'A14', 'A15', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 target\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0      +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560      +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824      +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3      +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0      +"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target의 +,-를 이후 처리를 원할하게 하기위해 0과 1로 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list=[]\n",
    "for i in df.target:\n",
    "    if i == '+':\n",
    "        target_list.append(0)\n",
    "    else:\n",
    "        target_list.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15  target\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0       0\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560       0\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824       0\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3       0\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target']=target_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 타입 확인 시 연속형 척도가 범주형 척도로 분류 된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1         object\n",
       "A2         object\n",
       "A3        float64\n",
       "A4         object\n",
       "A5         object\n",
       "A6         object\n",
       "A7         object\n",
       "A8        float64\n",
       "A9         object\n",
       "A10        object\n",
       "A11         int64\n",
       "A12        object\n",
       "A13        object\n",
       "A14        object\n",
       "A15         int64\n",
       "target      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list=['A1','A4','A5','A6','A9','A10','A12','A13']\n",
    "ratio_list=['A2','A3','A8','A11','A14','A15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 척도별로 리스트를 만들어 feature들의 이름을 할당하고 척도를 변경하면 '?'라는 문자가 연속형 척도에 포함되어있음을 알 수 있다. 따라서 이를 적절히 처리하여야한다.\n",
    "feature마다 '?'가 있는지 확인하고 어떤 열에 몇개가 있는지 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 1\n",
      "A2 1\n",
      "A4 1\n",
      "A5 1\n",
      "A6 1\n",
      "A7 1\n",
      "A14 1\n"
     ]
    }
   ],
   "source": [
    "nan_list=[]\n",
    "for i in df.columns:\n",
    "    count=0\n",
    "    if '?' in list(df[i].values):\n",
    "        count+=1\n",
    "        print(i,count)\n",
    "        nan_list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop 함수를 사용하여 ? 값을 nan(결측치)로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nan_list:\n",
    "    df.drop(df[df[i] == '?'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수별로 알맞은 척도를 지정해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_list:\n",
    "    features[i]=pd.Categorical(features[i])\n",
    "for i in ratio_list:\n",
    "    features[i]=pd.to_numeric(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     category\n",
       "A2      float64\n",
       "A3      float64\n",
       "A4     category\n",
       "A5     category\n",
       "A6     category\n",
       "A7       object\n",
       "A8      float64\n",
       "A9     category\n",
       "A10    category\n",
       "A11       int64\n",
       "A12    category\n",
       "A13    category\n",
       "A14       int64\n",
       "A15       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 명목, 범주형 척도를 get_dummies를 사용하여 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A1_a</th>\n",
       "      <th>A1_b</th>\n",
       "      <th>A4_l</th>\n",
       "      <th>A4_u</th>\n",
       "      <th>...</th>\n",
       "      <th>A7_z</th>\n",
       "      <th>A9_f</th>\n",
       "      <th>A9_t</th>\n",
       "      <th>A10_f</th>\n",
       "      <th>A10_t</th>\n",
       "      <th>A12_f</th>\n",
       "      <th>A12_t</th>\n",
       "      <th>A13_g</th>\n",
       "      <th>A13_p</th>\n",
       "      <th>A13_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>3.04</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A2     A3    A8  A11  A14  A15  A1_a  A1_b  A4_l  A4_u  ...    A7_z  \\\n",
       "0  30.83  0.000  1.25    1  202    0     0     1     0     1  ...       0   \n",
       "1  58.67  4.460  3.04    6   43  560     1     0     0     1  ...       0   \n",
       "2  24.50  0.500  1.50    0  280  824     1     0     0     1  ...       0   \n",
       "3  27.83  1.540  3.75    5  100    3     0     1     0     1  ...       0   \n",
       "4  20.17  5.625  1.71    0  120    0     0     1     0     1  ...       0   \n",
       "\n",
       "   A9_f  A9_t  A10_f  A10_t  A12_f  A12_t  A13_g  A13_p  A13_s  \n",
       "0     0     1      0      1      1      0      1      0      0  \n",
       "1     0     1      0      1      1      0      1      0      0  \n",
       "2     0     1      1      0      1      0      1      0      0  \n",
       "3     0     1      0      1      0      1      1      0      0  \n",
       "4     0     1      1      0      1      0      0      0      1  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn의 train_test_split을 사용해 학습데이터와 테스트데이터를 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=11\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features,df.target,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinju\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.optimizers import SGD,Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier\n",
    "![tree](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/CART_tree_titanic_survivors_KOR.png/525px-CART_tree_titanic_survivors_KOR.png)\n",
    "\n",
    "---\n",
    "위 그림과 같이 데이터를 적절한 분할 기준 또는 분할 테스트에 따라 부분 집합들로 나누는 과정이다. 이는 반복되며, max_depth가 default나 끝까지로 설정되어있을 경우 분할로 인해 더 이상 새로운 예측 값이 추가되지 않거나 부분 집합의 노드가 목표 변수와 같은 값을 지닐 때까지 계속된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold 방식을 사용한다. (분류에는 StratifiedKFold를 대부분 사용한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 모델 별로 최적의 hyper parameter를 찾기위해 GridSearchCV를 사용할 것이다. \n",
    " GridSearchCV는 sklearn이 제공하는 모델 선택에 도움을 주는 패키지로 train 데이터 내부에 validation 데이터를(kfold와 유사) 두어 성능을 확인함으로써 train 데이터를 학습시킬 때 가장 최적의 파라미터를 선택할 수 있도록 도와준다. 아래와 같이 중요한 hyper parameter에 들어갈 수 있는 값들을 사전형식으로 주면 그 중 최적의 파라미터를 선택할 수 있게 도와준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree의 경우 max_depth를 중요한 파라미터로 생각하며 완벽히 나뉠 때까지(default=None)로 설정한다면 오버피팅될 가능성이 높다. 따라서 적절한 깊이를 주어야 일반화가 용이하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'max_depth': [5,7,10,15,None], 'random_state':list(range(1,20))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=GridSearchCV(DecisionTreeClassifier(), params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [5, 7, 10, 15, None], 'random_state': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8658536585365854"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict={'score':tree.score(X_test,y_test), 'f1':f1_score(y_test, pred), 'recall':recall_score(y_test, pred), 'precision':precision_score(y_test, pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8764044943820224,\n",
       " 'precision': 0.8478260869565217,\n",
       " 'recall': 0.9069767441860465,\n",
       " 'score': 0.8658536585365854}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchcv 결과 max_depth가 5이며 random_state가 7일 때 가장 높은 정확도, 결과를 출력하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'random_state': 7}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-Support Vector Classification\n",
    "\n",
    "---\n",
    "    데이터를 분류할 수 있는 초평면(점선)의 마진(분류 데이터 사이의 거리)을 최대화하여 기준이 되는 경계(support vector)로 분류경계면을 찾는 방법이다. \n",
    "![svm](http://1.bp.blogspot.com/-NXaQRDHnCM0/Wmxciwina8I/AAAAAAAACgc/T8UKdKZSx7glaauna_-_sMPjrHSSbmo6QCK4BGAYYCw/s1600/svm5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC에서는 커널을 결정하는 kernel과 margin(넓이)를 결정하는 gamma가 중요한 hyper parameter이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'kernel': ['rbf'], 'gamma':[0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=GridSearchCV(SVC(), params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['rbf'], 'gamma': [0.01, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_dict={'score':tree.score(X_test,y_test), 'f1':f1_score(y_test, pred), 'recall':recall_score(y_test, pred), 'precision':precision_score(y_test, pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6549707602339181,\n",
       " 'precision': 0.6588235294117647,\n",
       " 'recall': 0.6511627906976745,\n",
       " 'score': 0.8658536585365854}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchcv 결과 rbf kernel, gamma가 0.01일 때 가장 좋은 성능을 보였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier\n",
    "![rfc](https://upload.wikimedia.org/wikipedia/commons/3/36/%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8_%ED%95%99%EC%8A%B5%EA%B3%BC%EC%A0%95_%EB%B0%B0%EA%B9%85.png)\n",
    "___\n",
    " 랜덤으로 서로 조금씩 다른 특성을 갖는 트리(Decision Tree)들을 결합(배깅, 부트스트랩)하여 데이터에 대해 훈련된 기초 분류기를 생성한다. 이 후 학습 결과를 종합하여 n_estimators 개의 트리들 중 가장 많이 나온 값, 즉 다수결의 원칙으로 가장 적절한 모델을 선정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree와 마찬가지로 max_depth와 랜덤으로 생성해 결합할 tree의 수를 결정하는 n_estimators가 중요한 hyper parameter이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'max_depth': [5,7,10,15,None], 'n_estimators': [50,100,150]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=GridSearchCV(RandomForestClassifier(), params, cv=kf)\n",
    "rfc.fit(X_train,y_train)\n",
    "pred=rfc.predict(X_test)\n",
    "rfc_dict={'score':rfc.score(X_test,y_test), 'f1':f1_score(y_test, pred), 'recall':recall_score(y_test, pred), 'precision':precision_score(y_test, pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8685714285714285,\n",
       " 'precision': 0.8539325842696629,\n",
       " 'recall': 0.8837209302325582,\n",
       " 'score': 0.8597560975609756}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search 결과 max_depth를 최대로하여 완전히 분류될 때까지 주는 None과 estimators가 100개일 때 가장 좋은 성능을 보였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 100}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier\n",
    "![ada](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1542651255/image_1_joyt3x.png)\n",
    "___\n",
    " 성능 향상을 위하여 다른 많은형태(머신러닝의 다양한 기법 포함)의 학습 알고리즘을 랜덤으로 생성, 결합하여 사용하는 알고리즘이다.이 알고리즘의 결과와 실제 결과의 오차를 구하고 이를 역전파 알고리즘을 통해 최소화하며 weight를 수정하고 결과를 개선해간다. 따라서 어떤 형태의 학습 알고리즘과 결합할지도 parameter로 조정할 수 있으며 이를 n_estimators 개수만큼 결합해 다수결로 가장 좋은 모델을 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성할 학습 알고리즘 개수를 정할 n_estimators와 역전파로 weight를 수정할 때 쓰일 learning_rate를 다양하게 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'n_estimators': [50,100,150], 'learning_rate':[0.01,0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=GridSearchCV(AdaBoostClassifier(), params, cv=kf)\n",
    "abc.fit(X_train,y_train)\n",
    "pred=abc.predict(X_test)\n",
    "abc_dict={'score':abc.score(X_test,y_test), 'f1':f1_score(y_test, pred), 'recall':recall_score(y_test, pred), 'precision':precision_score(y_test, pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8620689655172414,\n",
       " 'precision': 0.8522727272727273,\n",
       " 'recall': 0.872093023255814,\n",
       " 'score': 0.8536585365853658}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate가 0.1 일 때, 개수가 100개일 때 가장 좋은 성능을 보였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'n_estimators': 100}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron\n",
    "![mlp](https://scikit-learn.org/stable/_images/multilayerperceptron_network.png)\n",
    "\n",
    "---\n",
    " 기존 단층 퍼셉트론, 단층신경망에 히든레이어의 층을 추가한 모델으로 입력층과 출력층 사이에 히든레이어를 두어 학습마다 가중치를 업데이트하여 가장 최적의 가중치를 찾아가는 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층을 거칠 때마다 가중치와 계산에 사용할 활성화함수, 결과를 구할 solver를 조정하여 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'activation': ['tanh','relu'], 'solver':['adam','sgd']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=GridSearchCV(MLPClassifier(), params, cv=kf)\n",
    "mlp.fit(X_train,y_train)\n",
    "pred=mlp.predict(X_test)\n",
    "mlp_dict={'score':mlp.score(X_test,y_test), 'f1':f1_score(y_test, pred), 'recall':recall_score(y_test, pred), 'precision':precision_score(y_test, pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7664670658682634,\n",
       " 'precision': 0.7901234567901234,\n",
       " 'recall': 0.7441860465116279,\n",
       " 'score': 0.7621951219512195}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch 결과 activation function이 tanh이고 solver가 adam일 때 가장 좋은 결과가 나왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh', 'solver': 'adam'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple DNN\n",
    "![DNN](http://dlwiki.finfra.com/_img/5-1.png)\n",
    "\n",
    "---\n",
    " MLP와 유사하나 MLP와 달리 심층신경망 (Deep Neural Network)는 입력층과 출력층 사이에 여러 개의 은닉층으로 이뤄진 인공신경망이다. 마찬가지로 비선형관계 또한 모델링 가능하며 역전파를 통해 weight를 수정해가며 정확도를 높인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inputs= X_train.shape[1]\n",
    "nb_units_hl_1=40\n",
    "nb_units_hl_2=20\n",
    "nb_outputs=pd.get_dummies(y_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN 함수를 만들어 정의한다. 히든레이어 2층이며 각각 40, 20개의 노드를 가진다. 활성화 함수는 sigmoid를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN(optimizer, lr):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_units_hl_1,input_dim=nb_inputs,activation='sigmoid'))\n",
    "    model.add(Dense(nb_units_hl_2 , activation='sigmoid'))\n",
    "    model.add(Dense(nb_outputs, activation='sigmoid'))\n",
    "    \n",
    "    if optimizer == 'rmsprop':\n",
    "        optim=RMSprop(lr=lr)\n",
    "    elif optimizer == 'adam' :\n",
    "        optim=Adam(lr=lr)\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model = KerasClassifier(build_fn=DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras 신경망 역시 함수로 packing 했을 경우 그리드서치를 활용할 수 있다. MLP의 solver와 유사한 optimizer, learning_rate, 전체 알고리즘을 반복할 횟수인 epochs, 학습 개수 단위인 batches를 조정하여 적절한 값을 찾아본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['adam','rmsprop']\n",
    "lr=[0.001,0.01]\n",
    "epochs = [10,30]\n",
    "batches = [32]\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(k_model,param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 645us/step - loss: 0.6785 - acc: 0.6687\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6634 - acc: 0.6626\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6537 - acc: 0.6350\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6439 - acc: 0.6626\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 43us/step - loss: 0.6345 - acc: 0.6687\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6240 - acc: 0.6902\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.6157 - acc: 0.7117\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.6078 - acc: 0.7086\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6034 - acc: 0.7117\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5997 - acc: 0.7055\n",
      "163/163 [==============================] - 0s 214us/step\n",
      "326/326 [==============================] - 0s 31us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 548us/step - loss: 0.7020 - acc: 0.4110\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.6765 - acc: 0.7117\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6604 - acc: 0.7147\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.6467 - acc: 0.7117\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6354 - acc: 0.7209\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.6264 - acc: 0.7178\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6156 - acc: 0.7270\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.6050 - acc: 0.7209\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5965 - acc: 0.7209\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5870 - acc: 0.7362\n",
      "163/163 [==============================] - 0s 239us/step\n",
      "326/326 [==============================] - 0s 28us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 596us/step - loss: 0.7336 - acc: 0.4693\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6989 - acc: 0.4724\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6814 - acc: 0.6319\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.6683 - acc: 0.6656\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.6597 - acc: 0.7025\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.6535 - acc: 0.7147\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 43us/step - loss: 0.6461 - acc: 0.7209\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6376 - acc: 0.7178\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6288 - acc: 0.7178\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6214 - acc: 0.7209\n",
      "163/163 [==============================] - 0s 288us/step\n",
      "326/326 [==============================] - 0s 28us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 541us/step - loss: 0.6964 - acc: 0.5552\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6781 - acc: 0.5552\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6675 - acc: 0.5552\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6576 - acc: 0.5613\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6503 - acc: 0.5798\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 43us/step - loss: 0.6427 - acc: 0.5982\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 43us/step - loss: 0.6357 - acc: 0.7055\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6289 - acc: 0.6994\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6221 - acc: 0.6963\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6162 - acc: 0.7178\n",
      "163/163 [==============================] - 0s 379us/step\n",
      "326/326 [==============================] - 0s 28us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 636us/step - loss: 0.7240 - acc: 0.5767\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6787 - acc: 0.5767\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6569 - acc: 0.5767\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6463 - acc: 0.5767\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6342 - acc: 0.5767\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6234 - acc: 0.6595\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6135 - acc: 0.7178\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6054 - acc: 0.7147\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5971 - acc: 0.7270\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5923 - acc: 0.7423\n",
      "163/163 [==============================] - 0s 404us/step\n",
      "326/326 [==============================] - 0s 24us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 600us/step - loss: 0.7301 - acc: 0.5307\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.7016 - acc: 0.5307\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6825 - acc: 0.5307\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6709 - acc: 0.5307\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6608 - acc: 0.6166\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6530 - acc: 0.6810\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6434 - acc: 0.6871\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 43us/step - loss: 0.6366 - acc: 0.7209\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6290 - acc: 0.7239\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6228 - acc: 0.7117\n",
      "163/163 [==============================] - 0s 416us/step\n",
      "326/326 [==============================] - 0s 31us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 829us/step - loss: 0.6327 - acc: 0.6871\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5855 - acc: 0.7117\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5705 - acc: 0.7178\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5649 - acc: 0.7331\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5418 - acc: 0.7485\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5047 - acc: 0.7914\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.4670 - acc: 0.8037\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4306 - acc: 0.8160\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.4142 - acc: 0.8098\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.3931 - acc: 0.8221\n",
      "163/163 [==============================] - 0s 520us/step\n",
      "326/326 [==============================] - 0s 34us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.6157 - acc: 0.6963\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5702 - acc: 0.7362\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5639 - acc: 0.7454\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5542 - acc: 0.7638\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5431 - acc: 0.7423\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5249 - acc: 0.7669\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5132 - acc: 0.7577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5162 - acc: 0.7669\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.4756 - acc: 0.7883\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.4691 - acc: 0.7883\n",
      "163/163 [==============================] - 0s 618us/step\n",
      "326/326 [==============================] - 0s 40us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 948us/step - loss: 0.6638 - acc: 0.6288\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6227 - acc: 0.6871\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6064 - acc: 0.7086\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5936 - acc: 0.7025\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5772 - acc: 0.7301\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5800 - acc: 0.7178\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5479 - acc: 0.7393\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5605 - acc: 0.7055\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5412 - acc: 0.7393\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5101 - acc: 0.7607\n",
      "163/163 [==============================] - 0s 538us/step\n",
      "326/326 [==============================] - 0s 37us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 893us/step - loss: 0.6759 - acc: 0.6043\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6001 - acc: 0.6902\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5846 - acc: 0.7147\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5719 - acc: 0.7301\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5411 - acc: 0.7362\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5251 - acc: 0.7699\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5072 - acc: 0.7791\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5005 - acc: 0.8037\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4656 - acc: 0.8190\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.4575 - acc: 0.8006\n",
      "163/163 [==============================] - 0s 618us/step\n",
      "326/326 [==============================] - 0s 34us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 957us/step - loss: 0.6241 - acc: 0.6656\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5773 - acc: 0.7331\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5701 - acc: 0.7331\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5629 - acc: 0.7454\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5494 - acc: 0.7485\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5487 - acc: 0.7607\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5439 - acc: 0.7669\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5152 - acc: 0.7669\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5105 - acc: 0.7638\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.4872 - acc: 0.7638\n",
      "163/163 [==============================] - 0s 698us/step\n",
      "326/326 [==============================] - 0s 31us/step\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 0s 988us/step - loss: 0.6935 - acc: 0.6104\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 0s 43us/step - loss: 0.6191 - acc: 0.6902\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.6041 - acc: 0.6871\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5894 - acc: 0.7209\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5771 - acc: 0.7147\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5688 - acc: 0.7362\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5624 - acc: 0.7485\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5368 - acc: 0.7423\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5273 - acc: 0.7577\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5296 - acc: 0.7515\n",
      "163/163 [==============================] - 0s 795us/step\n",
      "326/326 [==============================] - 0s 34us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.7689 - acc: 0.4448\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.7162 - acc: 0.4417\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6849 - acc: 0.6258\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6700 - acc: 0.6626\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6580 - acc: 0.6687\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6481 - acc: 0.6779\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6389 - acc: 0.6902\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6303 - acc: 0.7025\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6219 - acc: 0.7147\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6146 - acc: 0.7086\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6079 - acc: 0.7209\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6017 - acc: 0.7209\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5965 - acc: 0.7209\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5916 - acc: 0.7178\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5874 - acc: 0.7209\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5815 - acc: 0.7301\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5787 - acc: 0.7270\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5733 - acc: 0.7239\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5700 - acc: 0.7331\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5663 - acc: 0.7270\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5633 - acc: 0.7270\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5611 - acc: 0.7301\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5577 - acc: 0.7331\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5534 - acc: 0.7331\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5471 - acc: 0.7331\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5417 - acc: 0.7301\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5376 - acc: 0.7301\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5324 - acc: 0.7393\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5263 - acc: 0.7454\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5187 - acc: 0.7546\n",
      "163/163 [==============================] - 0s 789us/step\n",
      "326/326 [==============================] - 0s 46us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.7658 - acc: 0.4233\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.7008 - acc: 0.4325\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6649 - acc: 0.7147\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6398 - acc: 0.7454\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 43us/step - loss: 0.6249 - acc: 0.7178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.6122 - acc: 0.7209\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6022 - acc: 0.7423\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5912 - acc: 0.7362\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5838 - acc: 0.7393\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5780 - acc: 0.7393\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5747 - acc: 0.7393\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5716 - acc: 0.7393\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5680 - acc: 0.7393\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5662 - acc: 0.7393\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5638 - acc: 0.7362\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5619 - acc: 0.7423\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5600 - acc: 0.7393\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5566 - acc: 0.7454\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5530 - acc: 0.7423\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5502 - acc: 0.7423\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5463 - acc: 0.7423\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5390 - acc: 0.7485\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5412 - acc: 0.7515\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5358 - acc: 0.7515\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5316 - acc: 0.7485\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5290 - acc: 0.7485\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5230 - acc: 0.7515\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5207 - acc: 0.7515\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5167 - acc: 0.7515\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5112 - acc: 0.7607\n",
      "163/163 [==============================] - 0s 765us/step\n",
      "326/326 [==============================] - 0s 37us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.7207 - acc: 0.4693\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6875 - acc: 0.4693\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6690 - acc: 0.5951\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6593 - acc: 0.6933\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6508 - acc: 0.6810\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6448 - acc: 0.6810\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6385 - acc: 0.6810\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.6320 - acc: 0.6810\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.6263 - acc: 0.6902\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.6216 - acc: 0.6933\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6160 - acc: 0.6994\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6110 - acc: 0.6994\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.6070 - acc: 0.6994\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.6026 - acc: 0.6933\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6003 - acc: 0.7147\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5982 - acc: 0.7178\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5943 - acc: 0.7209\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5916 - acc: 0.7178\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5888 - acc: 0.7147\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5852 - acc: 0.7147\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5820 - acc: 0.7117\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5785 - acc: 0.7117\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5739 - acc: 0.7209\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5709 - acc: 0.7239\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5639 - acc: 0.7209\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5593 - acc: 0.7178\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5496 - acc: 0.7270\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5486 - acc: 0.7301\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5425 - acc: 0.7423\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5320 - acc: 0.7577\n",
      "163/163 [==============================] - 0s 850us/step\n",
      "326/326 [==============================] - 0s 34us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.7023 - acc: 0.4448\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6619 - acc: 0.6411\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6395 - acc: 0.7055\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.6263 - acc: 0.6994\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.6169 - acc: 0.7117\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.6098 - acc: 0.7147\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 43us/step - loss: 0.6027 - acc: 0.7147\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5967 - acc: 0.7117\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5916 - acc: 0.7055\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5876 - acc: 0.7117\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5839 - acc: 0.7055\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5802 - acc: 0.7055\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5773 - acc: 0.7117\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5741 - acc: 0.7209\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5709 - acc: 0.7086\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5651 - acc: 0.7147\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5621 - acc: 0.7178\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5560 - acc: 0.7117\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5547 - acc: 0.7209\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5513 - acc: 0.7209\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5484 - acc: 0.7301\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5413 - acc: 0.7270\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.5385 - acc: 0.7362\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5350 - acc: 0.7331\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.5279 - acc: 0.7454\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5228 - acc: 0.7454\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5132 - acc: 0.7515\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 0s 49us/step - loss: 0.5162 - acc: 0.7638\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4965 - acc: 0.7669\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4934 - acc: 0.7853\n",
      "163/163 [==============================] - 0s 881us/step\n",
      "326/326 [==============================] - 0s 40us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.7108 - acc: 0.5767\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.6833 - acc: 0.5767\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.6674 - acc: 0.5767\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.6563 - acc: 0.5767\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.6460 - acc: 0.5767\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.6379 - acc: 0.5767\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 73us/step - loss: 0.6290 - acc: 0.5859\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.6205 - acc: 0.7055\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 92us/step - loss: 0.6109 - acc: 0.7270\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 101us/step - loss: 0.6030 - acc: 0.7301\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5958 - acc: 0.7423\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.5895 - acc: 0.7515\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 86us/step - loss: 0.5855 - acc: 0.7454\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5786 - acc: 0.7454\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 95us/step - loss: 0.5743 - acc: 0.7485\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5697 - acc: 0.7454\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.5651 - acc: 0.7423\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5608 - acc: 0.7423\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5581 - acc: 0.7454\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.5545 - acc: 0.7423\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.5527 - acc: 0.7423\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.5500 - acc: 0.7454\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 98us/step - loss: 0.5464 - acc: 0.7485\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5440 - acc: 0.7515\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 92us/step - loss: 0.5407 - acc: 0.7546\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5383 - acc: 0.7546\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 101us/step - loss: 0.5364 - acc: 0.7638\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.5355 - acc: 0.7546\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5296 - acc: 0.7607\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5288 - acc: 0.7607\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "326/326 [==============================] - 0s 49us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.6853 - acc: 0.5491\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 95us/step - loss: 0.6668 - acc: 0.6503\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.6548 - acc: 0.6933\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 113us/step - loss: 0.6450 - acc: 0.6902\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.6368 - acc: 0.6871\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 98us/step - loss: 0.6278 - acc: 0.6840\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.6215 - acc: 0.6871\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 101us/step - loss: 0.6161 - acc: 0.6963\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.6124 - acc: 0.7025\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.6079 - acc: 0.7055\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.6048 - acc: 0.7086\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.6035 - acc: 0.7117\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.6009 - acc: 0.7178\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.6018 - acc: 0.7086\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.5992 - acc: 0.7086\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5965 - acc: 0.7117\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5948 - acc: 0.7147\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5936 - acc: 0.7239\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5929 - acc: 0.7239\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.5901 - acc: 0.7270\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 86us/step - loss: 0.5887 - acc: 0.7147\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5869 - acc: 0.7239\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5863 - acc: 0.7147\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5842 - acc: 0.7178\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 86us/step - loss: 0.5809 - acc: 0.7147\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5785 - acc: 0.7178\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 101us/step - loss: 0.5778 - acc: 0.7178\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5742 - acc: 0.7178\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5707 - acc: 0.7178\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5675 - acc: 0.7239\n",
      "163/163 [==============================] - 0s 1ms/step\n",
      "326/326 [==============================] - 0s 49us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.6430 - acc: 0.6687\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5965 - acc: 0.6994\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5914 - acc: 0.7117\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5812 - acc: 0.7178\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5825 - acc: 0.7178\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5721 - acc: 0.7362\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5640 - acc: 0.7239\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 83us/step - loss: 0.5430 - acc: 0.7362\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5199 - acc: 0.7699\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4793 - acc: 0.7853\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4336 - acc: 0.8252\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4593 - acc: 0.7853\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 104us/step - loss: 0.4341 - acc: 0.8190\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 98us/step - loss: 0.4439 - acc: 0.8067\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 83us/step - loss: 0.4293 - acc: 0.8037\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 98us/step - loss: 0.4653 - acc: 0.8037\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 73us/step - loss: 0.4495 - acc: 0.8006\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 122us/step - loss: 0.4081 - acc: 0.8221\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 0s 70us/step - loss: 0.4290 - acc: 0.8067\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 80us/step - loss: 0.3989 - acc: 0.8190\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4428 - acc: 0.8221\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 83us/step - loss: 0.4113 - acc: 0.8221\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4254 - acc: 0.8252\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4222 - acc: 0.8067\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4271 - acc: 0.8374\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 80us/step - loss: 0.3892 - acc: 0.8313\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 73us/step - loss: 0.3932 - acc: 0.8466\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 83us/step - loss: 0.3675 - acc: 0.8558\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.3619 - acc: 0.8558\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.3557 - acc: 0.8528\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "326/326 [==============================] - 0s 43us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.6522 - acc: 0.6288\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5684 - acc: 0.7362\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 95us/step - loss: 0.5715 - acc: 0.7301\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5557 - acc: 0.7577\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5478 - acc: 0.7454\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5406 - acc: 0.7485\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5371 - acc: 0.7638\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5132 - acc: 0.7577\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5063 - acc: 0.7546\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4963 - acc: 0.7699\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4743 - acc: 0.7822\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4458 - acc: 0.7914\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4441 - acc: 0.8037\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4442 - acc: 0.7975\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4429 - acc: 0.8098\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4289 - acc: 0.8067\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4937 - acc: 0.7638\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.4336 - acc: 0.7853\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4272 - acc: 0.8190\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 73us/step - loss: 0.4531 - acc: 0.7791\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4383 - acc: 0.8129\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4031 - acc: 0.8221\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4060 - acc: 0.8129\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4197 - acc: 0.8098\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.3998 - acc: 0.8160\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.3851 - acc: 0.8190\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4498 - acc: 0.7761\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 83us/step - loss: 0.4173 - acc: 0.7791\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4090 - acc: 0.8129\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4058 - acc: 0.8129\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "326/326 [==============================] - 0s 46us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 1s 3ms/step - loss: 0.6629 - acc: 0.6258\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.6182 - acc: 0.6902\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.6013 - acc: 0.6933\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5963 - acc: 0.7239\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5870 - acc: 0.7301\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5655 - acc: 0.7301\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5508 - acc: 0.7301\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5341 - acc: 0.7362\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.5211 - acc: 0.7485\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5032 - acc: 0.7730\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5078 - acc: 0.7699\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5014 - acc: 0.7822\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5217 - acc: 0.7699\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4650 - acc: 0.7914\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4905 - acc: 0.7730\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4864 - acc: 0.7791\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4735 - acc: 0.7761\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 73us/step - loss: 0.4750 - acc: 0.7730\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4451 - acc: 0.7945\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 80us/step - loss: 0.5623 - acc: 0.7117\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4571 - acc: 0.7975\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 92us/step - loss: 0.4791 - acc: 0.7975\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4362 - acc: 0.7945\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 80us/step - loss: 0.4567 - acc: 0.8006\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4344 - acc: 0.7730\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 101us/step - loss: 0.4382 - acc: 0.7975\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4305 - acc: 0.8190\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 98us/step - loss: 0.4839 - acc: 0.7669\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4306 - acc: 0.8037\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 98us/step - loss: 0.4219 - acc: 0.7945\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "326/326 [==============================] - 0s 43us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.6600 - acc: 0.6626\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5879 - acc: 0.7147\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5553 - acc: 0.7423\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.5544 - acc: 0.7147\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5396 - acc: 0.7607\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5019 - acc: 0.7730\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4881 - acc: 0.7975\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4739 - acc: 0.7945\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4627 - acc: 0.7853\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 0s 58us/step - loss: 0.4472 - acc: 0.7945\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 73us/step - loss: 0.4502 - acc: 0.8006\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4812 - acc: 0.7822\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4303 - acc: 0.8190\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4364 - acc: 0.7945\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.3990 - acc: 0.8374\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4231 - acc: 0.8221\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4349 - acc: 0.7822\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.3930 - acc: 0.8252\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4427 - acc: 0.8067\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4154 - acc: 0.8190\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4236 - acc: 0.8252\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.3626 - acc: 0.8405\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.3974 - acc: 0.8190\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.3930 - acc: 0.8129\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.3572 - acc: 0.8436\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4196 - acc: 0.8160\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.3882 - acc: 0.8129\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4189 - acc: 0.8190\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.3891 - acc: 0.8282\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.3595 - acc: 0.8405\n",
      "163/163 [==============================] - 0s 1ms/step\n",
      "326/326 [==============================] - 0s 46us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.6231 - acc: 0.6442\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5851 - acc: 0.7270\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.5491 - acc: 0.7577\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 73us/step - loss: 0.5651 - acc: 0.7331\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.5352 - acc: 0.7577\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5253 - acc: 0.7607\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4933 - acc: 0.7669\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 76us/step - loss: 0.5066 - acc: 0.7761\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4876 - acc: 0.7853\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 73us/step - loss: 0.4907 - acc: 0.7883\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4565 - acc: 0.7853\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4629 - acc: 0.7945\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4549 - acc: 0.7822\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4636 - acc: 0.7975\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.4663 - acc: 0.7791\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.4663 - acc: 0.7914\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4173 - acc: 0.8006\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4278 - acc: 0.8190\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4150 - acc: 0.8160\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.3831 - acc: 0.8344\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4086 - acc: 0.8190\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4533 - acc: 0.7975\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.3908 - acc: 0.8282\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.3764 - acc: 0.8374\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4268 - acc: 0.8006\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4199 - acc: 0.8098\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 70us/step - loss: 0.4091 - acc: 0.8252\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.3909 - acc: 0.8160\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.3486 - acc: 0.8558\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.3841 - acc: 0.8405\n",
      "163/163 [==============================] - 0s 1ms/step\n",
      "326/326 [==============================] - 0s 40us/step\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.6490 - acc: 0.6043\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.6019 - acc: 0.6963\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5998 - acc: 0.7086\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5868 - acc: 0.7270\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 0s 49us/step - loss: 0.5726 - acc: 0.7331\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.5447 - acc: 0.7454\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5455 - acc: 0.7638\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5352 - acc: 0.7423\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.5118 - acc: 0.7699\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.5258 - acc: 0.7362\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.5017 - acc: 0.8006\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4634 - acc: 0.7945\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 0s 64us/step - loss: 0.4740 - acc: 0.8037\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4591 - acc: 0.7975\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4568 - acc: 0.7761\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.4667 - acc: 0.7546\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4261 - acc: 0.8067\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.4662 - acc: 0.8006\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4604 - acc: 0.7975\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.4539 - acc: 0.7669\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.4364 - acc: 0.7914\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.4253 - acc: 0.7975\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 0s 46us/step - loss: 0.4179 - acc: 0.8160\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4012 - acc: 0.8129\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 0s 52us/step - loss: 0.4636 - acc: 0.7730\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 0s 61us/step - loss: 0.4126 - acc: 0.8160\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.3983 - acc: 0.8221\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 0s 67us/step - loss: 0.4082 - acc: 0.8098\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 0s 55us/step - loss: 0.4229 - acc: 0.8006\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 0s 58us/step - loss: 0.3953 - acc: 0.8282\n",
      "163/163 [==============================] - 0s 1ms/step\n",
      "326/326 [==============================] - 0s 37us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489/489 [==============================] - 1s 1ms/step - loss: 0.6419 - acc: 0.6626\n",
      "Epoch 2/10\n",
      "489/489 [==============================] - 0s 61us/step - loss: 0.5921 - acc: 0.7157\n",
      "Epoch 3/10\n",
      "489/489 [==============================] - 0s 51us/step - loss: 0.5771 - acc: 0.7260\n",
      "Epoch 4/10\n",
      "489/489 [==============================] - 0s 51us/step - loss: 0.5660 - acc: 0.7301\n",
      "Epoch 5/10\n",
      "489/489 [==============================] - 0s 49us/step - loss: 0.5474 - acc: 0.7342\n",
      "Epoch 6/10\n",
      "489/489 [==============================] - 0s 51us/step - loss: 0.5254 - acc: 0.7607\n",
      "Epoch 7/10\n",
      "489/489 [==============================] - 0s 51us/step - loss: 0.5005 - acc: 0.7771\n",
      "Epoch 8/10\n",
      "489/489 [==============================] - 0s 51us/step - loss: 0.4834 - acc: 0.7710\n",
      "Epoch 9/10\n",
      "489/489 [==============================] - 0s 51us/step - loss: 0.4829 - acc: 0.7791\n",
      "Epoch 10/10\n",
      "489/489 [==============================] - 0s 49us/step - loss: 0.4752 - acc: 0.7791\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=grid_result.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "dnn_dict={'score':grid_result.score(X_test,y_test), 'f1':f1_score(y_test, pred), 'recall':recall_score(y_test, pred), 'precision':precision_score(y_test, pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7555555555555555,\n",
       " 'precision': 0.723404255319149,\n",
       " 'recall': 0.7906976744186046,\n",
       " 'score': 0.7317073170731707}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch결과 학습 단위가 32개이고 반복회수 10번, learning_rate 0.01, opimizer가 adam일 때 가장 좋은 결과가 나왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32, 'epochs': 10, 'lr': 0.01, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 총 6가지 모델을 사용하였으며 각각의 결과는 다음과 같다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8764044943820224,\n",
       " 'precision': 0.8478260869565217,\n",
       " 'recall': 0.9069767441860465,\n",
       " 'score': 0.8658536585365854}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6549707602339181,\n",
       " 'precision': 0.6588235294117647,\n",
       " 'recall': 0.6511627906976745,\n",
       " 'score': 0.8658536585365854}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8685714285714285,\n",
       " 'precision': 0.8539325842696629,\n",
       " 'recall': 0.8837209302325582,\n",
       " 'score': 0.8597560975609756}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8620689655172414,\n",
       " 'precision': 0.8522727272727273,\n",
       " 'recall': 0.872093023255814,\n",
       " 'score': 0.8536585365853658}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7664670658682634,\n",
       " 'precision': 0.7901234567901234,\n",
       " 'recall': 0.7441860465116279,\n",
       " 'score': 0.7621951219512195}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7555555555555555,\n",
       " 'precision': 0.723404255319149,\n",
       " 'recall': 0.7906976744186046,\n",
       " 'score': 0.7317073170731707}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체적인 비교를 위해 f1,precision,recall,score의 평균을 살펴본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score is 87.427\n",
      "avg score is 70.77\n",
      "avg score is 86.65\n",
      "avg score is 86.002\n",
      "avg score is 76.574\n",
      "avg score is 75.034\n"
     ]
    }
   ],
   "source": [
    "for i in [tree_dict,svc_dict,rfc_dict,abc_dict,mlp_dict,dnn_dict]:\n",
    "    tmp_list=[v for v in i.values()]\n",
    "    print('avg score is '+str(round(np.mean(tmp_list)*100,3)))\n",
    "    avg_score.append(round(np.mean(tmp_list)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17288122cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['tree','svc','rfc','abc','mlp','dnn'],avg_score,color=['r','b','g','purple','yellow','gray'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 머신러닝 기법에서는 Decision Tree가 가장 높은 평균점수가 나왔다.\n",
    " 가능한 많은 parameter를 설정해 gridsearchcv를 해야하고, 그러면 결과가 바뀔 수도 있지만 간단한 조정만으로 결과가 좋게 나왔다는 점만으로도 충분히 Decision Tree를 선택할 수 있다. 또한 Decision Tree는 다른 모델들과 달리 분류가 어떤식으로 진행되는지 볼 수 있기 때문에 장점이 있는 모델이다. 따라서 Decision Tree를 선택할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN이 시간을 가지고 수정해간다면 가장 좋은 모델이 될 것이다.\n",
    " 대체로 신경망의 성능이 머신러닝의 성능 보다 뛰어난 것은 많은 사례를 통해 입증된 사실이다. 신경망은 활성화함수, 히든레이어의 수, 노드의 수, 옵티마이져, 에폭 등 성능을 개선할 수 있는 방법이 더욱 많으며 모델이 가질 수 형태 또한 무궁무진하다. 따라서 간단한 테스트에서는 머신러닝 기법보다 약간 정확도가 낮지만 시간을 가지고 그리드서치를 통해 hyperparameter를 수정해간다면 결국 신경망(DNN)의 성능이 가장 뛰어날 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래 그림은 graphviz를 통해 선택한 Decision Tree 모델을 시각화 한 그림이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tree](https://github.com/taejinhyun/credit_clf/blob/master/tree.png?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
